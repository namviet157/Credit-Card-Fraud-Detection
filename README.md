# Credit Card Fraud Detection

**Credit Card Fraud Detection** lÃ  má»™t dá»± Ã¡n phÃ¡t hiá»‡n gian láº­n tháº» tÃ­n dá»¥ng Ä‘Æ°á»£c xÃ¢y dá»±ng hoÃ n toÃ n báº±ng **NumPy**, khÃ´ng sá»­ dá»¥ng cÃ¡c thÆ° viá»‡n Machine Learning cÃ³ sáºµn nhÆ° scikit-learn hay Pandas. Dá»± Ã¡n nÃ y táº­p trung vÃ o viá»‡c hiá»ƒu sÃ¢u cÃ¡c thuáº­t toÃ¡n Machine Learning báº±ng cÃ¡ch implement tá»« Ä‘áº§u, tá»« khÃ¡m phÃ¡ dá»¯ liá»‡u, tiá»n xá»­ lÃ½ Ä‘áº¿n huáº¥n luyá»‡n mÃ´ hÃ¬nh Logistic Regression.

## ğŸ“‹ Má»¥c lá»¥c

1. [Giá»›i thiá»‡u](#1-giá»›i-thiá»‡u)
2. [Dataset](#2-dataset)
3. [Method](#3-method)
4. [Installation & Setup](#4-installation--setup)
5. [Usage](#5-usage)
6. [Results & Visualizations](#6-results--visualizations)
7. [Project Structure](#7-project-structure)
8. [Challenges & Solutions](#8-challenges--solutions)
9. [Future Improvements](#9-future-improvements)
10. [Contributors](#10-contributors)
11. [License](#11-license)

---

## 1. Giá»›i thiá»‡u

### 1.1. MÃ´ táº£ bÃ i toÃ¡n

**BÃ i toÃ¡n**: PhÃ¡t hiá»‡n gian láº­n trong cÃ¡c giao dá»‹ch tháº» tÃ­n dá»¥ng

- **Äáº§u vÃ o**: ThÃ´ng tin vá» cÃ¡c giao dá»‹ch tháº» tÃ­n dá»¥ng bao gá»“m:
  - `Time`: Thá»i gian giao dá»‹ch (tÃ­nh báº±ng giÃ¢y tá»« giao dá»‹ch Ä‘áº§u tiÃªn)
  - `V1-V28`: 28 features Ä‘Ã£ Ä‘Æ°á»£c PCA transform (áº©n danh Ä‘á»ƒ báº£o máº­t)
  - `Amount`: Sá»‘ tiá»n giao dá»‹ch
  
- **Äáº§u ra**: Dá»± Ä‘oÃ¡n giao dá»‹ch cÃ³ pháº£i lÃ  gian láº­n hay khÃ´ng
  - `0`: Giao dá»‹ch bÃ¬nh thÆ°á»ng (Normal)
  - `1`: Giao dá»‹ch gian láº­n (Fraud)

- **Loáº¡i bÃ i toÃ¡n**: Binary Classification vá»›i **class imbalance nghiÃªm trá»ng**
  - Tá»· lá»‡ gian láº­n chá»‰ chiáº¿m **0.17%** tá»•ng sá»‘ giao dá»‹ch
  - ÄÃ¢y lÃ  má»™t trong nhá»¯ng thÃ¡ch thá»©c lá»›n nháº¥t cá»§a bÃ i toÃ¡n

### 1.2. Äá»™ng lá»±c vÃ  á»©ng dá»¥ng thá»±c táº¿

Fraud detection lÃ  má»™t váº¥n Ä‘á» cá»±c ká»³ quan trá»ng trong ngÃ nh tÃ i chÃ­nh vÃ  ngÃ¢n hÃ ng:

1. **Tá»•n tháº¥t tÃ i chÃ­nh**: 
   - CÃ¡c giao dá»‹ch gian láº­n gÃ¢y thiá»‡t háº¡i hÃ ng tá»· USD má»—i nÄƒm trÃªn toÃ n tháº¿ giá»›i
   - Má»—i giao dá»‹ch gian láº­n khÃ´ng Ä‘Æ°á»£c phÃ¡t hiá»‡n Ä‘á»u gÃ¢y thiá»‡t háº¡i trá»±c tiáº¿p

2. **Báº£o vá»‡ khÃ¡ch hÃ ng**:
   - PhÃ¡t hiá»‡n sá»›m giÃºp báº£o vá»‡ khÃ¡ch hÃ ng khá»i cÃ¡c hoáº¡t Ä‘á»™ng gian láº­n
   - Giáº£m thiá»ƒu rá»§i ro máº¥t tiá»n vÃ  thÃ´ng tin cÃ¡ nhÃ¢n

3. **TuÃ¢n thá»§ quy Ä‘á»‹nh**:
   - CÃ¡c ngÃ¢n hÃ ng vÃ  tá»• chá»©c tÃ i chÃ­nh cáº§n cÃ³ há»‡ thá»‘ng phÃ¡t hiá»‡n gian láº­n hiá»‡u quáº£ Ä‘á»ƒ tuÃ¢n thá»§ cÃ¡c quy Ä‘á»‹nh phÃ¡p lÃ½

4. **Xá»­ lÃ½ real-time**:
   - Cáº§n phÃ¡t hiá»‡n gian láº­n trong thá»i gian thá»±c Ä‘á»ƒ ngÄƒn cháº·n ká»‹p thá»i
   - YÃªu cáº§u mÃ´ hÃ¬nh cÃ³ Ä‘á»™ chÃ­nh xÃ¡c cao vÃ  tá»‘c Ä‘á»™ xá»­ lÃ½ nhanh

5. **CÃ¢n báº±ng giá»¯a Precision vÃ  Recall**:
   - **Precision cao**: TrÃ¡nh lÃ m phiá»n khÃ¡ch hÃ ng báº±ng cÃ¡c cáº£nh bÃ¡o giáº£ (False Positives)
   - **Recall cao**: TrÃ¡nh bá» lá»t cÃ¡c giao dá»‹ch gian láº­n (False Negatives) - Ä‘iá»u nÃ y cá»±c ká»³ quan trá»ng

### 1.3. Má»¥c tiÃªu cá»¥ thá»ƒ

#### Má»¥c tiÃªu ká»¹ thuáº­t:
1. **LÃ m chá»§ NumPy**:
   - Sá»­ dá»¥ng NumPy Ä‘á»ƒ xá»­ lÃ½ toÃ n bá»™ dá»¯ liá»‡u (khÃ´ng dÃ¹ng Pandas)
   - Implement cÃ¡c thuáº­t toÃ¡n ML tá»« Ä‘áº§u báº±ng NumPy
   - Tá»‘i Æ°u hÃ³a code vá»›i vectorization vÃ  broadcasting
   - TrÃ¡nh sá»­ dá»¥ng for loops khÃ´ng cáº§n thiáº¿t

2. **PhÃ¢n tÃ­ch dá»¯ liá»‡u sÃ¢u**:
   - KhÃ¡m phÃ¡ vÃ  hiá»ƒu vá» dataset
   - PhÃ¡t hiá»‡n patterns vÃ  insights tá»« dá»¯ liá»‡u
   - Xá»­ lÃ½ class imbalance
   - PhÃ¢n tÃ­ch correlation vÃ  feature importance

3. **Modeling tá»« Ä‘áº§u**:
   - Implement Logistic Regression hoÃ n chá»‰nh vá»›i Gradient Descent
   - Hiá»ƒu sÃ¢u vá» loss function, gradient computation
   - ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh vá»›i cÃ¡c metrics phÃ¹ há»£p cho imbalanced data

#### Má»¥c tiÃªu há»c thuáº­t:
- Hiá»ƒu rÃµ cÃ¡ch hoáº¡t Ä‘á»™ng cá»§a cÃ¡c thuáº­t toÃ¡n ML cÆ¡ báº£n
- Náº¯m vá»¯ng cÃ¡c ká»¹ thuáº­t xá»­ lÃ½ dá»¯ liá»‡u
- Ãp dá»¥ng kiáº¿n thá»©c toÃ¡n há»c vÃ o thá»±c táº¿

---

## 2. Dataset

### 2.1. Nguá»“n dá»¯ liá»‡u

- **Dataset**: Credit Card Fraud Detection
- **Nguá»“n**: [Kaggle - Credit Card Fraud Detection](https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud)
- **Tá»• chá»©c**: ULB (UniversitÃ© Libre de Bruxelles) Machine Learning Group
- **KÃ­ch thÆ°á»›c**: 284,807 giao dá»‹ch
- **Thá»i gian thu tháº­p**: Giao dá»‹ch trong 2 ngÃ y (khoáº£ng 48 giá»)

### 2.2. MÃ´ táº£ cÃ¡c features

| Feature | MÃ´ táº£ | Kiá»ƒu dá»¯ liá»‡u | Äáº·c Ä‘iá»ƒm |
|---------|-------|--------------|----------|
| **Time** | Sá»‘ giÃ¢y giá»¯a giao dá»‹ch Ä‘áº§u tiÃªn vÃ  giao dá»‹ch nÃ y | Float | Pháº¡m vi: 0 - 172,792 giÃ¢y |
| **V1-V28** | 28 features Ä‘Ã£ Ä‘Æ°á»£c PCA transform | Float | ÄÃ£ Ä‘Æ°á»£c chuáº©n hÃ³a, mean â‰ˆ 0, std â‰ˆ 1 |
| **Amount** | Sá»‘ tiá»n giao dá»‹ch (USD) | Float | Pháº¡m vi: $0 - $25,691.16, phÃ¢n phá»‘i lá»‡ch pháº£i |
| **Class** | NhÃ£n (0 = bÃ¬nh thÆ°á»ng, 1 = gian láº­n) | Integer | Binary classification target |

**LÆ°u Ã½ quan trá»ng**: 
- CÃ¡c features V1-V28 Ä‘Ã£ Ä‘Æ°á»£c PCA transform Ä‘á»ƒ **báº£o máº­t thÃ´ng tin nháº¡y cáº£m** cá»§a khÃ¡ch hÃ ng
- ÄÃ¢y lÃ  cÃ¡ch tiáº¿p cáº­n phá»• biáº¿n trong cÃ¡c bÃ i toÃ¡n tÃ i chÃ­nh Ä‘á»ƒ tuÃ¢n thá»§ quy Ä‘á»‹nh báº£o vá»‡ dá»¯ liá»‡u cÃ¡ nhÃ¢n
- CÃ¡c features gá»‘c (nhÆ° sá»‘ tháº», tÃªn khÃ¡ch hÃ ng, Ä‘á»‹a chá»‰) khÃ´ng Ä‘Æ°á»£c tiáº¿t lá»™

### 2.3. KÃ­ch thÆ°á»›c vÃ  Ä‘áº·c Ä‘iá»ƒm dá»¯ liá»‡u

#### Thá»‘ng kÃª tá»•ng quan:
- **Tá»•ng sá»‘ samples**: 284,807
- **Sá»‘ features**: 30 (Time + V1-V28 + Amount)
- **Missing values**: **KhÃ´ng cÃ³** (0 missing values)
- **Outliers**: CÃ³ nhiá»u outliers, Ä‘áº·c biá»‡t trong:
  - Feature `Amount`: 31,904 outliers (11.20%) theo IQR method
  - Feature `V27`: 39,163 outliers (13.75%)
  - Feature `V28`: 30,342 outliers (10.65%)

#### Class Distribution (PhÃ¢n phá»‘i lá»›p):

```
Class 0 (Normal):  284,315 samples (99.83%)
Class 1 (Fraud):       492 samples (0.17%)
Imbalance ratio: 0.0017 (fraud/normal)
```

**PhÃ¢n tÃ­ch class imbalance**:
- ÄÃ¢y lÃ  má»™t trong nhá»¯ng dataset cÃ³ **class imbalance nghiÃªm trá»ng nháº¥t**
- Tá»· lá»‡ 1:578 (1 giao dá»‹ch gian láº­n trÃªn 578 giao dá»‹ch bÃ¬nh thÆ°á»ng)
- Äiá»u nÃ y khiáº¿n viá»‡c Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh trá»Ÿ nÃªn khÃ³ khÄƒn:
  - Accuracy khÃ´ng pháº£i lÃ  metric tá»‘t (mÃ´ hÃ¬nh chá»‰ cáº§n dá»± Ä‘oÃ¡n táº¥t cáº£ lÃ  "Normal" cÅ©ng Ä‘áº¡t 99.83% accuracy)
  - Cáº§n táº­p trung vÃ o **Precision**, **Recall**, **F1-Score** vÃ  **AUC**

#### Äáº·c Ä‘iá»ƒm phÃ¢n phá»‘i:

**Time Feature**:
- Mean: 94,813.86 giÃ¢y (~26.34 giá»)
- Median: 84,692 giÃ¢y (~23.53 giá»)
- PhÃ¢n phá»‘i: HÆ¡i lá»‡ch trÃ¡i (Skewness â‰ˆ -0.036)
- **Insight**: CÃ³ pattern theo chu ká»³ ngÃ y/Ä‘Ãªm, tá»· lá»‡ gian láº­n cao hÆ¡n vÃ o ban Ä‘Ãªm (2-4h sÃ¡ng)

**Amount Feature**:
- Mean: $88.35
- Median: $22.00
- Max: $25,691.16
- **PhÃ¢n phá»‘i lá»‡ch pháº£i nghiÃªm trá»ng**:
  - Skewness: 16.98 (ráº¥t cao)
  - Kurtosis: 845.07 (phÃ¢n phá»‘i cá»±c ká»³ nhá»n)
- **So sÃ¡nh Normal vs Fraud**:
  - Normal transactions: Mean = $88.29, Median = $22.00
  - Fraud transactions: Mean = $122.21, Median = $9.25
  - **Káº¿t luáº­n**: Giao dá»‹ch gian láº­n cÃ³ giÃ¡ trá»‹ trung bÃ¬nh cao hÆ¡n nhÆ°ng median tháº¥p hÆ¡n

**PCA Features (V1-V28)**:
- Táº¥t cáº£ Ä‘á»u cÃ³ mean â‰ˆ 0 (do Ä‘Ã£ Ä‘Æ°á»£c PCA transform)
- Standard deviation giáº£m dáº§n tá»« V1 Ä‘áº¿n V28 (tá»« 1.96 xuá»‘ng 0.33)
- **TÃ­nh trá»±c giao**: CÃ¡c features nÃ y háº§u nhÆ° khÃ´ng tÆ°Æ¡ng quan vá»›i nhau (Ä‘áº·c tÃ­nh cá»§a PCA)
- **Top features quan trá»ng nháº¥t** (dá»±a trÃªn sá»± khÃ¡c biá»‡t giá»¯a Normal vÃ  Fraud):
  1. V3: Diff = 7.05
  2. V14: Diff = 6.98
  3. V17: Diff = 6.68
  4. V12: Diff = 6.27
  5. V10: Diff = 5.69

---

## 3. Method

### 3.1. Quy trÃ¬nh xá»­ lÃ½ dá»¯ liá»‡u

#### 3.1.1. Data Loading

**Ã tÆ°á»Ÿng triá»ƒn khai**: Sá»­ dá»¥ng NumPy Ä‘á»ƒ Ä‘á»c CSV file thay vÃ¬ Pandas

- Sá»­ dá»¥ng `np.genfromtxt()` vá»›i `dtype=str` Ä‘á»ƒ Ä‘á»c file CSV vÃ  giá»¯ nguyÃªn format ban Ä‘áº§u
- Xá»­ lÃ½ header báº±ng `np.char.strip()` Ä‘á»ƒ loáº¡i bá» dáº¥u ngoáº·c kÃ©p
- TÃ¡ch header vÃ  dá»¯ liá»‡u, sau Ä‘Ã³ convert sang `float64` Ä‘á»ƒ cÃ³ thá»ƒ tÃ­nh toÃ¡n

**Káº¿t quáº£**: Ma tráº­n dá»¯ liá»‡u shape (284807, 31) - 30 features + 1 target

#### 3.1.2. Data Exploration

**Ã tÆ°á»Ÿng triá»ƒn khai**: PhÃ¢n tÃ­ch toÃ n diá»‡n dá»¯ liá»‡u Ä‘á»ƒ hiá»ƒu rÃµ Ä‘áº·c Ä‘iá»ƒm vÃ  patterns

**a) Kiá»ƒm tra dá»¯ liá»‡u thiáº¿u**:
- Sá»­ dá»¥ng `np.isnan()` vÃ  `np.isinf()` Ä‘á»ƒ phÃ¡t hiá»‡n cÃ¡c giÃ¡ trá»‹ khÃ´ng há»£p lá»‡
- TÃ­nh tá»•ng sá»‘ missing values theo tá»«ng cá»™t

**b) TÃ­nh toÃ¡n thá»‘ng kÃª mÃ´ táº£**:
- Sá»­ dá»¥ng cÃ¡c hÃ m NumPy vectorized Ä‘á»ƒ tÃ­nh Mean, Median, Std, Variance, Min, Max
- TÃ­nh Quartiles (Q1, Q2, Q3) báº±ng `np.percentile()`
- Implement tá»« Ä‘áº§u cÃ¡c hÃ m tÃ­nh Skewness vÃ  Kurtosis báº±ng cÃ´ng thá»©c toÃ¡n há»c

**c) PhÃ¢n tÃ­ch class distribution**:
- Sá»­ dá»¥ng `np.unique()` vá»›i `return_counts=True` Ä‘á»ƒ Ä‘áº¿m sá»‘ lÆ°á»£ng má»—i class
- TÃ­nh tá»· lá»‡ pháº§n trÄƒm vÃ  visualize báº±ng bar chart vÃ  pie chart

**d) PhÃ¢n tÃ­ch features**:
- **Time feature**: Chuyá»ƒn Ä‘á»•i tá»« giÃ¢y sang giá», phÃ¢n tÃ­ch theo chu ká»³ ngÃ y/Ä‘Ãªm
- **Amount feature**: So sÃ¡nh phÃ¢n phá»‘i giá»¯a Normal vÃ  Fraud báº±ng histogram vÃ  boxplot
- **PCA features**: Visualize phÃ¢n phá»‘i cá»§a V1-V9 Ä‘á»ƒ hiá»ƒu Ä‘áº·c Ä‘iá»ƒm

**e) Correlation analysis**:
- TÃ­nh correlation matrix báº±ng cÃ¡ch chuáº©n hÃ³a dá»¯ liá»‡u (mean=0, std=1) rá»“i sá»­ dá»¥ng `np.corrcoef()`
- Visualize báº±ng heatmap Ä‘á»ƒ phÃ¡t hiá»‡n cÃ¡c features cÃ³ tÆ°Æ¡ng quan máº¡nh

**f) Feature importance**:
- So sÃ¡nh giÃ¡ trá»‹ trung bÃ¬nh giá»¯a Normal vÃ  Fraud cho tá»«ng feature
- XÃ¡c Ä‘á»‹nh top features cÃ³ sá»± khÃ¡c biá»‡t lá»›n nháº¥t (dÃ¹ng `np.abs()` vÃ  `np.argsort()`)

**g) Statistical hypothesis testing**:
- Thá»±c hiá»‡n T-test Ä‘á»ƒ kiá»ƒm tra sá»± khÃ¡c biá»‡t vá» Amount giá»¯a Normal vÃ  Fraud
- TÃ­nh t-statistic vÃ  p-value tá»« cÃ´ng thá»©c toÃ¡n há»c
- Káº¿t quáº£: p-value = 0.0034 < 0.05 â†’ BÃ¡c bá» H0, cÃ³ sá»± khÃ¡c biá»‡t cÃ³ Ã½ nghÄ©a thá»‘ng kÃª

#### 3.1.3. Data Preprocessing

**a) Missing Values Handling**:

Máº·c dÃ¹ dataset khÃ´ng cÃ³ missing values, nhÆ°ng Ä‘Ã£ implement cÃ¡c phÆ°Æ¡ng phÃ¡p xá»­ lÃ½ Ä‘á»ƒ demo:

1. **Mean Imputation**: Äiá»n báº±ng giÃ¡ trá»‹ trung bÃ¬nh cá»§a cá»™t Ä‘Ã³
2. **Median Imputation**: Äiá»n báº±ng giÃ¡ trá»‹ trung vá»‹ cá»§a cá»™t Ä‘Ã³
3. **Specific Value Imputation**: Äiá»n báº±ng má»™t giÃ¡ trá»‹ cá»¥ thá»ƒ (vÃ­ dá»¥: -999)
4. **Linear Regression Imputation**: Sá»­ dá»¥ng má»‘i tÆ°Æ¡ng quan giá»¯a Time vÃ  Amount Ä‘á»ƒ dá»± Ä‘oÃ¡n giÃ¡ trá»‹ Amount bá»‹ thiáº¿u. Sá»­ dá»¥ng Normal Equation Ä‘á»ƒ tÃ¬m há»‡ sá»‘ há»“i quy tuyáº¿n tÃ­nh.

**b) Outlier Detection**:

**PhÆ°Æ¡ng phÃ¡p 1: IQR Method**
- TÃ­nh Q1, Q3 vÃ  IQR cho tá»«ng feature
- XÃ¡c Ä‘á»‹nh outliers lÃ  cÃ¡c Ä‘iá»ƒm náº±m ngoÃ i khoáº£ng [Q1 - 1.5Ã—IQR, Q3 + 1.5Ã—IQR]
- **Káº¿t quáº£**: 370,372 outliers (4.33% tá»•ng sá»‘ data points)

**PhÆ°Æ¡ng phÃ¡p 2: Z-score Method**
- TÃ­nh mean vÃ  std cho tá»«ng feature
- TÃ­nh Z-score vÃ  xÃ¡c Ä‘á»‹nh outliers lÃ  cÃ¡c Ä‘iá»ƒm cÃ³ |Z-score| > 3.0
- **Káº¿t quáº£**: 83,598 outliers (0.98% tá»•ng sá»‘ data points)

**Quyáº¿t Ä‘á»‹nh**: **KHÃ”NG loáº¡i bá» outliers** vÃ¬:
- Trong bÃ i toÃ¡n fraud detection, outliers cÃ³ thá»ƒ chÃ­nh lÃ  cÃ¡c giao dá»‹ch gian láº­n
- Loáº¡i bá» outliers cÃ³ thá»ƒ lÃ m máº¥t Ä‘i nhá»¯ng máº«u quan trá»ng nháº¥t
- Thay vÃ o Ä‘Ã³, sá»­ dá»¥ng cÃ¡c phÆ°Æ¡ng phÃ¡p chuáº©n hÃ³a máº¡nh (robust scaling)

**c) Normalization & Standardization**:

**BÆ°á»›c 1: Log Transformation cho Amount**
- Sá»­ dá»¥ng `np.log1p()` (log(1+x)) Ä‘á»ƒ xá»­ lÃ½ phÃ¢n phá»‘i lá»‡ch pháº£i
- **LÃ½ do**: 
  - Amount cÃ³ skewness = 16.98 (ráº¥t cao)
  - Sau log transform: skewness giáº£m xuá»‘ng 0.16
  - GiÃºp phÃ¢n phá»‘i gáº§n vá»›i chuáº©n hÆ¡n

**BÆ°á»›c 2: Z-score Standardization**
- TÃ­nh mean vÃ  std cho tá»«ng feature sau khi log transform
- Chuáº©n hÃ³a: (x - mean) / std
- Xá»­ lÃ½ edge case: Náº¿u std = 0 thÃ¬ thay báº±ng 1 Ä‘á»ƒ trÃ¡nh division by zero
- **Káº¿t quáº£**: 
  - Mean â‰ˆ 0, Std â‰ˆ 1 cho táº¥t cáº£ features
  - PhÃ¹ há»£p vá»›i cÃ¡c thuáº­t toÃ¡n dá»±a trÃªn gradient (Logistic Regression)

**CÃ¡c phÆ°Æ¡ng phÃ¡p khÃ¡c Ä‘Ã£ thá»­ nghiá»‡m**:
- **Min-Max Normalization**: ÄÆ°a vá» [0, 1], nhÆ°ng bá»‹ áº£nh hÆ°á»Ÿng máº¡nh bá»Ÿi outliers
- **Decimal Scaling**: Ãt phá»• biáº¿n, kÃ©m hiá»‡u quáº£ hÆ¡n Z-score

**d) Train-Test Split**:

- Chia dá»¯ liá»‡u theo tá»· lá»‡ 80% train, 20% test
- Sá»­ dá»¥ng `np.random.shuffle()` vá»›i `random_state=42` Ä‘á»ƒ xÃ¡o trá»™n indices
- **KÃ­ch thÆ°á»›c táº­p dá»¯ liá»‡u**:
  - Train: **227,846** máº«u (Normal: 227,452, Fraud: 394)
  - Test: **56,961** máº«u (Normal: 56,863, Fraud: 98)
- **Báº£o toÃ n class distribution**: 
  - Train: 99.83% Normal, 0.17% Fraud
  - Test: 99.83% Normal, 0.17% Fraud
  - Imbalance ratio Ä‘Æ°á»£c báº£o toÃ n (~0.0017)

### 3.2. Thuáº­t toÃ¡n sá»­ dá»¥ng

#### 3.2.1. Logistic Regression

**CÃ´ng thá»©c toÃ¡n há»c**:

**1. Sigmoid Function**:
$$P(y=1|x) = \sigma(z) = \frac{1}{1 + e^{-z}}$$

vá»›i $z = w^T x + b = \sum_{i=1}^{n} w_i x_i + b$

**2. Loss Function (Binary Cross-Entropy)**:
$$L = -\frac{1}{m}\sum_{i=1}^{m}[y_i \log(\hat{y}_i) + (1-y_i)\log(1-\hat{y}_i)]$$

Trong Ä‘Ã³:
- $m$: sá»‘ lÆ°á»£ng samples
- $y_i$: nhÃ£n thá»±c táº¿ (0 hoáº·c 1)
- $\hat{y}_i = \sigma(w^T x_i + b)$: xÃ¡c suáº¥t dá»± Ä‘oÃ¡n

**3. Gradient Computation**:

Äáº¡o hÃ m cá»§a loss function theo weights:
$$\frac{\partial L}{\partial w} = \frac{1}{m}X^T(\hat{y} - y)$$

Äáº¡o hÃ m cá»§a loss function theo bias:
$$\frac{\partial L}{\partial b} = \frac{1}{m}\sum_{i=1}^{m}(\hat{y}_i - y_i)$$

**4. Update Rules (Gradient Descent)**:
$$w := w - \alpha \frac{\partial L}{\partial w}$$
$$b := b - \alpha \frac{\partial L}{\partial b}$$

Trong Ä‘Ã³ $\alpha$ lÃ  learning rate.

**Ã tÆ°á»Ÿng triá»ƒn khai**:

- **Vectorized operations**: Táº¥t cáº£ tÃ­nh toÃ¡n Ä‘á»u Ä‘Æ°á»£c vectorize, khÃ´ng dÃ¹ng for loops
  - Forward pass: Sá»­ dá»¥ng matrix multiplication `X @ weights + bias`
  - Gradient computation: Sá»­ dá»¥ng `np.einsum()` hoáº·c matrix multiplication Ä‘á»ƒ tÃ­nh gradient hiá»‡u quáº£
- **Broadcasting**: Sá»­ dá»¥ng broadcasting Ä‘á»ƒ tÃ­nh toÃ¡n hiá»‡u quáº£
- **Numerical stability**: 
  - Clip z values trong khoáº£ng [-500, 500] Ä‘á»ƒ trÃ¡nh overflow trong sigmoid
  - ThÃªm epsilon (1e-15) vÃ o log Ä‘á»ƒ trÃ¡nh log(0)
- **Convergence check**: Kiá»ƒm tra sá»± thay Ä‘á»•i cá»§a loss giá»¯a cÃ¡c iterations

**Hyperparameters**:
- Learning rate: 0.01
- Max iterations: 1000
- Tolerance: 1e-6 (Ä‘á»ƒ kiá»ƒm tra convergence)
- Random state: 42 (Ä‘áº£m báº£o reproducibility)

### 3.3. Evaluation Metrics

Trong bÃ i toÃ¡n imbalanced data, **Accuracy khÃ´ng pháº£i lÃ  metric tá»‘t**. CÃ¡c metrics quan trá»ng:

**1. Confusion Matrix**:

|                | Predicted Normal | Predicted Fraud |
|----------------|------------------|-----------------|
| **Actual Normal** | TN (True Negative) | FP (False Positive) |
| **Actual Fraud**  | FN (False Negative) | TP (True Positive) |

**2. Precision (Äá»™ chÃ­nh xÃ¡c dÆ°Æ¡ng tÃ­nh)**:
$$\text{Precision} = \frac{TP}{TP + FP}$$

Ã nghÄ©a: Trong sá»‘ cÃ¡c giao dá»‹ch mÃ´ hÃ¬nh dá»± Ä‘oÃ¡n lÃ  gian láº­n, bao nhiÃªu pháº§n trÄƒm lÃ  Ä‘Ãºng?

**3. Recall (Äá»™ nháº¡y)**:
$$\text{Recall} = \frac{TP}{TP + FN}$$

Ã nghÄ©a: MÃ´ hÃ¬nh phÃ¡t hiá»‡n Ä‘Æ°á»£c bao nhiÃªu pháº§n trÄƒm tá»•ng sá»‘ vá»¥ gian láº­n thá»±c táº¿?

**4. F1-Score (Trung bÃ¬nh Ä‘iá»u hÃ²a)**:
$$\text{F1-Score} = 2 \times \frac{\text{Precision} \times \text{Recall}}{\text{Precision} + \text{Recall}}$$

**5. AUC (Area Under ROC Curve)**:
- ROC Curve: Váº½ True Positive Rate (Recall) vs False Positive Rate
- AUC: Diá»‡n tÃ­ch dÆ°á»›i Ä‘Æ°á»ng cong ROC
- Metric tá»‘t nháº¥t cho imbalanced data vÃ¬ khÃ´ng phá»¥ thuá»™c vÃ o threshold

**Ã tÆ°á»Ÿng triá»ƒn khai**:

- **Confusion Matrix**: Sá»­ dá»¥ng boolean indexing vÃ  `np.sum()` Ä‘á»ƒ Ä‘áº¿m TN, FP, FN, TP
- **Precision/Recall/F1**: TÃ­nh tá»« confusion matrix vá»›i xá»­ lÃ½ edge case (chia cho 0)
- **ROC Curve**: 
  - Sáº¯p xáº¿p predictions theo score giáº£m dáº§n
  - Vá»›i má»—i threshold, tÃ­nh FPR vÃ  TPR
  - Sá»­ dá»¥ng `np.trapz()` Ä‘á»ƒ tÃ­nh diá»‡n tÃ­ch dÆ°á»›i Ä‘Æ°á»ng cong (AUC)

---

## 4. Installation & Setup

### 4.1. Requirements

- **Python**: 3.7 trá»Ÿ lÃªn
- **NumPy**: >= 1.21.0
- **Matplotlib**: >= 3.5.0 (cho visualization)
- **Seaborn**: >= 0.11.0 (cho visualization Ä‘áº¹p hÆ¡n)
- **Jupyter**: >= 1.0.0 (Ä‘á»ƒ cháº¡y notebooks)

### 4.2. Installation

**BÆ°á»›c 1: Clone repository** (náº¿u cÃ³)
```bash
git clone https://github.com/namviet157/Credit-Card-Fraud-Detection.git
cd Credit-Card-Fraud-Detection
```

**BÆ°á»›c 2: Táº¡o virtual environment**
```bash
# Windows
python -m venv venv
venv\Scripts\activate

# Linux/Mac
python3 -m venv venv
source venv/bin/activate
```

**BÆ°á»›c 3: Install dependencies**
```bash
pip install -r requirements.txt
```

Hoáº·c install tá»«ng package:
```bash
pip install numpy>=1.21.0 matplotlib>=3.5.0 seaborn>=0.11.0 jupyter
```

### 4.3. Dataset Setup

1. **Download dataset**:
   - Truy cáº­p [Kaggle - Credit Card Fraud Detection](https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud)
   - Download file `creditcard.csv`

2. **Äáº·t file vÃ o Ä‘Ãºng thÆ° má»¥c**:
   ```
   data/
   â””â”€â”€ raw/
       â””â”€â”€ creditcard.csv
   ```

3. **Kiá»ƒm tra cáº¥u trÃºc thÆ° má»¥c**:
   ```
   project/
   â”œâ”€â”€ data/
   â”‚   â”œâ”€â”€ raw/
   â”‚   â”‚   â””â”€â”€ creditcard.csv
   â”‚   â””â”€â”€ processed/
   â”œâ”€â”€ notebooks/
   â”‚   â”œâ”€â”€ 01_data_exploration.ipynb
   â”‚   â”œâ”€â”€ 02_preprocessing.ipynb
   â”‚   â””â”€â”€ 03_modeling.ipynb
   â”œâ”€â”€ requirements.txt
   â””â”€â”€ README.md
   ```

---

## 5. Usage

### 5.1. HÆ°á»›ng dáº«n cÃ¡ch cháº¡y tá»«ng pháº§n

#### 5.1.1. Data Exploration

**Cháº¡y notebook Ä‘áº§u tiÃªn**:
```
01_data_exploration.ipynb
```

**Notebook nÃ y sáº½ thá»±c hiá»‡n**:
1. Load dataset tá»« `data/raw/creditcard.csv` (284,807 giao dá»‹ch, 31 cá»™t)
2. Kiá»ƒm tra missing values (káº¿t quáº£: 0 missing values) vÃ  thá»‘ng kÃª cÆ¡ báº£n
3. PhÃ¢n tÃ­ch class distribution (99.83% Normal, 0.17% Fraud)
4. PhÃ¢n tÃ­ch cÃ¡c features quan trá»ng:
   - Time feature: Fraud rate cao nháº¥t lÃºc 2h sÃ¡ng (~1.71%)
   - Amount feature: So sÃ¡nh giá»¯a Normal vÃ  Fraud (Skewness = 16.98)
   - PCA features (V1-V28): PhÃ¢n tÃ­ch phÃ¢n phá»‘i
5. Correlation analysis giá»¯a cÃ¡c features
6. So sÃ¡nh features giá»¯a Normal vÃ  Fraud - Top features: V3, V14, V17, V12, V10
7. Feature engineering: Táº¡o rolling statistics (window=100)
8. Statistical hypothesis testing (T-test): p-value = 0.0034
9. Xá»­ lÃ½ missing values (demo cÃ¡c phÆ°Æ¡ng phÃ¡p: Mean, Median, Regression)

**Káº¿t quáº£ Ä‘áº§u ra**:
- Insights quan trá»ng vá» dá»¯ liá»‡u:
  - Class imbalance: 99.83% Normal, 0.17% Fraud
  - Fraud rate cao nháº¥t lÃºc 2h sÃ¡ng (~1.71%)
  - Top features quan trá»ng: V3, V14, V17, V12, V10
  - T-test: p-value = 0.0034 â†’ Sá»± khÃ¡c biá»‡t Amount cÃ³ Ã½ nghÄ©a thá»‘ng kÃª

#### 5.1.2. Data Preprocessing

**Cháº¡y notebook thá»© hai**:
```
02_preprocessing.ipynb
```

**Notebook nÃ y sáº½ thá»±c hiá»‡n**:
1. Load dá»¯ liá»‡u tá»« `data/raw/creditcard.csv`
2. **Outlier Detection**:
   - IQR Method: 370,372 outliers (4.33%)
   - Z-score Method: 83,598 outliers (0.98%)
   - Quyáº¿t Ä‘á»‹nh: KHÃ”NG loáº¡i bá» outliers (cÃ³ thá»ƒ lÃ  fraud)
3. **Normalization & Standardization**:
   - Min-Max Normalization: Bá»‹ áº£nh hÆ°á»Ÿng bá»Ÿi outliers
   - Z-score Standardization: Mean=0, Std=1
   - Log Transformation: Skewness giáº£m tá»« 16.98 xuá»‘ng 0.16
   - Decimal Scaling: So sÃ¡nh vá»›i cÃ¡c phÆ°Æ¡ng phÃ¡p khÃ¡c
4. **Ãp dá»¥ng preprocessing cuá»‘i cÃ¹ng**:
   - Log transform cho Amount
   - Z-score standardization cho táº¥t cáº£ features
5. **Train-Test Split**:
   - Chia 80% train, 20% test vá»›i `random_state=42`
   - Train: 227,846 máº«u (Normal: 227,452, Fraud: 394)
   - Test: 56,961 máº«u (Normal: 56,863, Fraud: 98)
   - Báº£o toÃ n class distribution (~0.17% Fraud trong cáº£ hai táº­p)
6. LÆ°u dá»¯ liá»‡u Ä‘Ã£ xá»­ lÃ½:
   - `X_train.npy`, `X_test.npy`: Train/test features
   - `y_train.npy`, `y_test.npy`: Train/test labels

**Káº¿t quáº£ Ä‘áº§u ra**:
- CÃ¡c file `.npy` trong `data/processed/` Ä‘á»ƒ sá»­ dá»¥ng cho modeling

#### 5.1.3. Modeling

**Cháº¡y notebook thá»© ba**:
```
03_modeling.ipynb
```

**Notebook nÃ y sáº½ thá»±c hiá»‡n**:
1. Load dá»¯ liá»‡u Ä‘Ã£ xá»­ lÃ½ tá»« notebook 02
2. **Implement Evaluation Metrics**:
   - Accuracy, Precision, Recall, F1-Score
   - Confusion Matrix
   - ROC Curve vÃ  AUC
3. **Implement Logistic Regression**:
   - Class LogisticRegression vá»›i Gradient Descent
   - Training vá»›i cÃ¡c hyperparameters (lr=0.01, max_iter=1000)
   - Visualize training loss history
4. **Evaluation vÃ  Threshold Optimization**:
   - Dá»± Ä‘oÃ¡n trÃªn test set vá»›i threshold máº·c Ä‘á»‹nh (0.5)
   - **Thá»­ nghiá»‡m vá»›i threshold = 0.2** Ä‘á»ƒ cáº£i thiá»‡n Recall
   - TÃ­nh cÃ¡c metrics cho cáº£ hai threshold
   - Váº½ Confusion Matrix
   - Váº½ ROC Curve vÃ  tÃ­nh AUC
5. **PhÃ¢n tÃ­ch káº¿t quáº£**:
   - So sÃ¡nh metrics giá»¯a threshold 0.5 vÃ  0.2
   - PhÃ¢n tÃ­ch Confusion Matrix
   - PhÃ¢n tÃ­ch ROC Curve vÃ  AUC

**Káº¿t quáº£ Ä‘áº§u ra**:
- **Threshold 0.5**: Precision=0.8333, Recall=0.4592, F1=0.5921
- **Threshold 0.2**: Precision=0.8041, Recall=0.7959, F1=0.8000
- AUC = 0.9748

### 5.2. LÆ°u Ã½ quan trá»ng

 **Thá»© tá»± cháº¡y**: Pháº£i cháº¡y theo thá»© tá»± 01 â†’ 02 â†’ 03 vÃ¬:
- Notebook 03 phá»¥ thuá»™c vÃ o output cá»§a notebook 02

 **Dataset**: Äáº£m báº£o file `creditcard.csv` Ä‘Ã£ Ä‘Æ°á»£c Ä‘áº·t trong `data/raw/` trÆ°á»›c khi cháº¡y

 **Memory**: Dataset khÃ¡ lá»›n (~150MB), Ä‘áº£m báº£o cÃ³ Ä‘á»§ RAM

---

## 6. Results & Visualizations

### 6.1. Káº¿t quáº£ Ä‘áº¡t Ä‘Æ°á»£c (Metrics)

#### 6.1.1. Logistic Regression

**Hyperparameters**:
- Learning rate: 0.01
- Max iterations: 1000
- Random state: 42

**Training Results**:
- Sá»‘ iterations thá»±c táº¿: 1000 (chÆ°a converge, nhÆ°ng loss Ä‘Ã£ á»•n Ä‘á»‹nh)
- Final training loss: **0.1095**
- Training loss giáº£m Ä‘á»u vÃ  mÆ°á»£t mÃ , khÃ´ng cÃ³ dáº¥u hiá»‡u overfitting

**Test Results (Threshold = 0.5)**:

| Metric | Value | Giáº£i thÃ­ch |
|--------|-------|------------|
| **Accuracy** | 0.9989 | Ráº¥t cao nhÆ°ng khÃ´ng cÃ³ Ã½ nghÄ©a trong bÃ i toÃ¡n imbalanced |
| **Precision** | 0.8333 | Tá»‘t - 83.33% cáº£nh bÃ¡o lÃ  Ä‘Ãºng |
| **Recall** | 0.4592 | Tháº¥p - Chá»‰ phÃ¡t hiá»‡n Ä‘Æ°á»£c 45.92% tá»•ng sá»‘ gian láº­n |
| **F1-Score** | 0.5921 | Trung bÃ¬nh - Bá»‹ kÃ©o xuá»‘ng do Recall tháº¥p |
| **AUC** | **0.9748** | Ráº¥t cao - MÃ´ hÃ¬nh cÃ³ kháº£ nÄƒng phÃ¢n loáº¡i tá»‘t |

**Test Results (Threshold = 0.2 - Tá»‘i Æ°u)**:

| Metric | Value | Giáº£i thÃ­ch |
|--------|-------|------------|
| **Accuracy** | 0.9993 | Duy trÃ¬ á»Ÿ má»©c cá»±c cao |
| **Precision** | 0.8041 | Tá»‘t - Giáº£m nháº¹ nhÆ°ng váº«n cháº¥p nháº­n Ä‘Æ°á»£c |
| **Recall** | **0.7959** | Cáº£i thiá»‡n Ä‘á»™t phÃ¡ - PhÃ¡t hiá»‡n Ä‘Æ°á»£c ~80% vá»¥ gian láº­n |
| **F1-Score** | **0.8000** | Tá»‘t - CÃ¢n báº±ng tá»‘t giá»¯a Precision vÃ  Recall |
| **AUC** | **0.9748** | Ráº¥t cao - MÃ´ hÃ¬nh cÃ³ kháº£ nÄƒng phÃ¢n loáº¡i tá»‘t |

**Confusion Matrix (Threshold = 0.2)**:

|                | Predicted Normal | Predicted Fraud |
|----------------|------------------|-----------------|
| **Actual Normal** | 56,844 (TN) | 19 (FP) |
| **Actual Fraud**  | 20 (FN) | 78 (TP) |

**PhÃ¢n tÃ­ch**:
-  **True Negatives (56,844)**: Äa sá»‘ giao dá»‹ch bÃ¬nh thÆ°á»ng Ä‘Æ°á»£c phÃ¢n loáº¡i Ä‘Ãºng
-  **True Positives (78)**: PhÃ¡t hiá»‡n Ä‘Æ°á»£c 78/98 vá»¥ gian láº­n (79.59%)
-  **False Positives (19)**: Chá»‰ cÃ³ 19 cáº£nh bÃ¡o giáº£ - Tá»· lá»‡ ráº¥t tháº¥p
-  **False Negatives (20)**: 20 vá»¥ gian láº­n bá»‹ bá» sÃ³t - Giáº£m Ä‘Ã¡ng ká»ƒ so vá»›i threshold 0.5

**Nháº­n Ä‘á»‹nh**:
- Viá»‡c háº¡ threshold tá»« 0.5 xuá»‘ng 0.2 mang láº¡i **cáº£i thiá»‡n Ä‘á»™t phÃ¡**
- **Recall tÄƒng tá»« 45.92% lÃªn 79.59%** - Báº¯t Ä‘Æ°á»£c thÃªm ráº¥t nhiá»u vá»¥ gian láº­n
- **F1-Score tÄƒng tá»« 0.5921 lÃªn 0.8000** - CÃ¢n báº±ng tá»‘t hÆ¡n háº³n
- Sá»± Ä‘Ã¡nh Ä‘á»•i hiá»‡u quáº£: Chá»‰ lÃ m phiá»n thÃªm 10 khÃ¡ch hÃ ng vÃ´ tá»™i Ä‘á»ƒ báº¯t Ä‘Æ°á»£c thÃªm 33 vá»¥ gian láº­n

### 6.2. HÃ¬nh áº£nh trá»±c quan hÃ³a káº¿t quáº£

#### 6.2.1. Data Exploration Visualizations

**1. Class Distribution**

**CÃ¢u há»i**: Dá»¯ liá»‡u cÃ³ máº¥t cÃ¢n báº±ng nhÆ° tháº¿ nÃ o vÃ  Ä‘iá»u nÃ y áº£nh hÆ°á»Ÿng gÃ¬ Ä‘áº¿n viá»‡c phÃ¡t hiá»‡n gian láº­n?

![](images/class_distribution.png)

**Biá»ƒu Ä‘á»“**: Bar chart vÃ  Pie chart hiá»ƒn thá»‹ sá»‘ lÆ°á»£ng vÃ  tá»· lá»‡ pháº§n trÄƒm cá»§a má»—i class

**Giáº£i thÃ­ch**:
- Bar chart cho tháº¥y sá»± chÃªnh lá»‡ch cá»±c lá»›n: 284,315 giao dá»‹ch bÃ¬nh thÆ°á»ng so vá»›i chá»‰ 492 giao dá»‹ch gian láº­n
- Pie chart minh há»a rÃµ rÃ ng tá»· lá»‡ 99.83% vs 0.17%
- **TÃ¡c Ä‘á»™ng**: 
  - Accuracy khÃ´ng pháº£i lÃ  metric tá»‘t (mÃ´ hÃ¬nh chá»‰ cáº§n dá»± Ä‘oÃ¡n táº¥t cáº£ lÃ  "Normal" váº«n Ä‘áº¡t 99.83% accuracy)
  - Cáº§n sá»­ dá»¥ng cÃ¡c metrics khÃ¡c nhÆ° Precision, Recall, F1-Score hoáº·c AUC
  - Cáº§n cÃ¢n nháº¯c cÃ¡c ká»¹ thuáº­t cÃ¢n báº±ng dá»¯ liá»‡u (SMOTE, Undersampling, Class Weights)

**2. Time Feature Analysis**

**CÃ¢u há»i**: CÃ³ sá»± khÃ¡c biá»‡t Ä‘Ã¡ng chÃº Ã½ nÃ o vá» tá»· lá»‡ gian láº­n giá»¯a cÃ¡c giá» trong ngÃ y khÃ´ng vÃ  nguyÃªn nhÃ¢n cÃ³ thá»ƒ lÃ  gÃ¬?

![](images/time_feature.png)

**Biá»ƒu Ä‘á»“**: 
- Histogram: PhÃ¢n phá»‘i giao dá»‹ch theo giá»
- Boxplot: So sÃ¡nh Time giá»¯a Normal vÃ  Fraud
- Line chart: Fraud rate theo giá» trong ngÃ y (0-23h)
- Line chart: Transaction volume theo giá»

**Giáº£i thÃ­ch**:
- **PhÃ¡t hiá»‡n quan trá»ng**: 
  - Giá» cÃ³ tá»· lá»‡ gian láº­n cao nháº¥t: **2-4 giá» sÃ¡ng** (tá»· lá»‡ cÃ³ thá»ƒ lÃªn tá»›i ~1.7%)
  - Giá» cÃ³ tá»· lá»‡ gian láº­n tháº¥p nháº¥t: **10-12 giá» trÆ°a** (tá»· lá»‡ ~0.05%)
  - Má»‘i quan há»‡ nghá»‹ch Ä‘áº£o: Khi sá»‘ lÆ°á»£ng giao dá»‹ch tá»•ng thá»ƒ giáº£m (ban Ä‘Ãªm), tá»· lá»‡ gian láº­n láº¡i tÄƒng

- **NguyÃªn nhÃ¢n cÃ³ thá»ƒ**:
  1. NgÆ°á»i dÃ¹ng Ã­t giÃ¡m sÃ¡t vÃ o ban Ä‘Ãªm (chá»§ tháº» Ä‘ang ngá»§)
  2. Thá»i gian pháº£n á»©ng cháº­m cá»§a há»‡ thá»‘ng cáº£nh bÃ¡o
  3. HÃ nh vi báº¥t thÆ°á»ng: Giao dá»‹ch vÃ o giá» khuya lÃ  báº¥t thÆ°á»ng Ä‘á»‘i vá»›i háº§u háº¿t ngÆ°á»i dÃ¹ng
  4. Tá»± Ä‘á»™ng hÃ³a táº¥n cÃ´ng: Nhiá»u cuá»™c táº¥n cÃ´ng gian láº­n Ä‘Æ°á»£c tá»± Ä‘á»™ng hÃ³a vÃ  cháº¡y vÃ o ban Ä‘Ãªm

- **Khuyáº¿n nghá»‹**:
  - TÄƒng cÆ°á»ng giÃ¡m sÃ¡t vÃ  cáº£nh bÃ¡o vÃ o cÃ¡c giá» ban Ä‘Ãªm (2-6h sÃ¡ng)
  - Sá»­ dá»¥ng Time nhÆ° má»™t Ä‘áº·c trÆ°ng quan trá»ng trong mÃ´ hÃ¬nh
  - Thiáº¿t láº­p há»‡ thá»‘ng cáº£nh bÃ¡o tá»± Ä‘á»™ng cho cÃ¡c giao dá»‹ch vÃ o giá» khuya

**3. Amount Feature Analysis**

**CÃ¢u há»i**: Giao dá»‹ch gian láº­n cÃ³ xu hÆ°á»›ng cÃ³ giÃ¡ trá»‹ cao hÆ¡n hay tháº¥p hÆ¡n giao dá»‹ch bÃ¬nh thÆ°á»ng?

![](images/amount.png)

**Biá»ƒu Ä‘á»“**: 
- Histogram: PhÃ¢n phá»‘i Amount (lá»‡ch pháº£i nghiÃªm trá»ng)
- Boxplot: So sÃ¡nh Amount giá»¯a Normal vÃ  Fraud

**Giáº£i thÃ­ch**:
- **Káº¿t quáº£ phÃ¢n tÃ­ch**:
  - **Trung bÃ¬nh**: Giao dá»‹ch gian láº­n cÃ³ giÃ¡ trá»‹ trung bÃ¬nh cao hÆ¡n ($122.21) so vá»›i giao dá»‹ch thÆ°á»ng ($88.29)
  - **Trung vá»‹**: Giao dá»‹ch gian láº­n cÃ³ trung vá»‹ tháº¥p hÆ¡n Ä‘Ã¡ng ká»ƒ ($9.25 vs $22.00)
  - **PhÃ¢n phá»‘i**: 
    - Giao dá»‹ch bÃ¬nh thÆ°á»ng: CÃ³ nhiá»u giao dá»‹ch giÃ¡ trá»‹ ráº¥t lá»›n (lÃªn tá»›i $25,691)
    - Giao dá»‹ch gian láº­n: GiÃ¡ trá»‹ tá»‘i Ä‘a tháº¥p hÆ¡n ($2,126), nhÆ°ng cÃ³ nhiá»u giao dá»‹ch nhá» hÆ¡n

- **Nháº­n Ä‘á»‹nh**:
  - Káº» gian láº­n thÆ°á»ng báº¯t Ä‘áº§u vá»›i cÃ¡c giao dá»‹ch nhá» Ä‘á»ƒ "thá»­ nghiá»‡m" tháº»
  - Sau Ä‘Ã³ tÄƒng dáº§n giÃ¡ trá»‹ Ä‘á»ƒ tá»‘i Ä‘a hÃ³a lá»£i nhuáº­n trÆ°á»›c khi bá»‹ phÃ¡t hiá»‡n
  - Há» trÃ¡nh cÃ¡c giao dá»‹ch quÃ¡ lá»›n vÃ¬ dá»… bá»‹ phÃ¡t hiá»‡n

- **Khuyáº¿n nghá»‹**:
  - Cáº£nh giÃ¡c vá»›i cÃ¡c giao dá»‹ch nhá» báº¥t thÆ°á»ng tá»« má»™t tháº»
  - Theo dÃµi xu hÆ°á»›ng tÄƒng giÃ¡ trá»‹ giao dá»‹ch
  - Káº¿t há»£p giÃ¡ trá»‹ vá»›i cÃ¡c Ä‘áº·c trÆ°ng khÃ¡c (thá»i gian, Ä‘á»‹a Ä‘iá»ƒm) Ä‘á»ƒ phÃ¡t hiá»‡n

**4. PCA Features Distribution**

**Biá»ƒu Ä‘á»“**: Histograms cho V1-V9 hiá»ƒn thá»‹ phÃ¢n phá»‘i cá»§a cÃ¡c PCA features

![](images/PCA_features.png)

**Giáº£i thÃ­ch**:
- Táº¥t cáº£ cÃ¡c biáº¿n nÃ y Ä‘á»u cÃ³ giÃ¡ trá»‹ trung bÃ¬nh (Mean) xáº¥p xá»‰ 0 (Ä‘áº·c tÃ­nh cá»§a dá»¯ liá»‡u Ä‘Ã£ qua PCA)
- HÃ¬nh dáº¡ng phÃ¢n phá»‘i Ä‘a dáº¡ng: má»™t sá»‘ biáº¿n tuÃ¢n theo phÃ¢n phá»‘i chuáº©n (hÃ¬nh chuÃ´ng), trong khi má»™t sá»‘ biáº¿n khÃ¡c cÃ³ phÃ¢n phá»‘i lá»‡ch hoáº·c nhá»n
- Nhá»¯ng biáº¿n cÃ³ sá»± khÃ¡c biá»‡t rÃµ rá»‡t vá» hÃ¬nh dáº¡ng phÃ¢n phá»‘i giá»¯a hai lá»›p sáº½ lÃ  nhá»¯ng biáº¿n quan trá»ng cho mÃ´ hÃ¬nh phÃ¢n loáº¡i

**5. Correlation Heatmap**

**Biá»ƒu Ä‘á»“**: Heatmap tÆ°Æ¡ng quan giá»¯a cÃ¡c features quan trá»ng (Time, Amount vÃ  10 biáº¿n V Ä‘áº§u tiÃªn)

![](images/feature_corr.png)

**Giáº£i thÃ­ch**:
- **TÃ­nh trá»±c giao cá»§a PCA**: CÃ¡c biáº¿n V1, V2,... V28 háº§u nhÆ° khÃ´ng cÃ³ tÆ°Æ¡ng quan vá»›i nhau (há»‡ sá»‘ tÆ°Æ¡ng quan gáº§n báº±ng 0). ÄÃ¢y lÃ  tÃ­nh cháº¥t cá»§a PCA giÃºp loáº¡i bá» Ä‘a cá»™ng tuyáº¿n.
- **Má»‘i quan há»‡ Time/Amount**: Cáº§n chÃº Ã½ xem `Amount` hoáº·c `Time` cÃ³ tÆ°Æ¡ng quan máº¡nh vá»›i biáº¿n V nÃ o khÃ´ng. VÃ­ dá»¥, náº¿u `Amount` cÃ³ tÆ°Æ¡ng quan cao vá»›i `V2` hoáº·c `V5`, Ä‘iá»u Ä‘Ã³ cÃ³ thá»ƒ giÃºp giáº£i thÃ­ch Ã½ nghÄ©a áº©n cá»§a cÃ¡c biáº¿n V nÃ y.

**6. Feature Engineering - Rolling Statistics**

**CÃ¢u há»i**: LÃ m tháº¿ nÃ o Ä‘á»ƒ phÃ¡t hiá»‡n cÃ¡c báº¥t thÆ°á»ng cá»¥c bá»™ mÃ  khÃ´ng chá»‰ dá»±a vÃ o giÃ¡ trá»‹ tuyá»‡t Ä‘á»‘i?

![](images/rolling_statistics.png)

**Biá»ƒu Ä‘á»“**: 
- Line chart: Amount vá»›i Rolling Mean vÃ  Rolling Std (cá»­a sá»• trÆ°á»£t 100 giao dá»‹ch)
- Scatter plot: Anomaly detection báº±ng Z-Score cá»¥c bá»™

**Giáº£i thÃ­ch**:
- **Ã tÆ°á»Ÿng**: Táº¡o cÃ¡c Ä‘áº·c trÆ°ng má»›i dá»±a trÃªn cá»­a sá»• trÆ°á»£t (Rolling Window) kÃ­ch thÆ°á»›c 100 giao dá»‹ch
- **CÃ¡c Ä‘áº·c trÆ°ng má»›i**:
  1. **Rolling Mean**: Xu hÆ°á»›ng trung bÃ¬nh cá»§a sá»‘ tiá»n trong 100 giao dá»‹ch gáº§n nháº¥t
  2. **Rolling Std**: Äá»™ biáº¿n Ä‘á»™ng cá»§a sá»‘ tiá»n
  3. **Local Z-Score**: Äo lÆ°á»ng xem giao dá»‹ch hiá»‡n táº¡i lá»‡ch bao nhiÃªu Ä‘á»™ lá»‡ch chuáº©n so vá»›i má»©c trung bÃ¬nh cá»¥c bá»™

- **Káº¿t quáº£**: 
  - Nhá»¯ng Ä‘iá»ƒm mÃ u Ä‘á» (Anomaly) lÃ  nhá»¯ng giao dá»‹ch cÃ³ Z-Score > 3
  - ÄÃ¢y lÃ  nhá»¯ng giao dá»‹ch Ä‘á»™t biáº¿n báº¥t thÆ°á»ng so vá»›i xu hÆ°á»›ng chi tiÃªu ngay trÆ°á»›c Ä‘Ã³
  - Má»™t chá»‰ bÃ¡o máº¡nh máº½ cho hÃ nh vi gian láº­n tiá»m áº©n

**7. Statistical Hypothesis Testing**

**CÃ¢u há»i**: Sá»± khÃ¡c biá»‡t vá» sá»‘ tiá»n trung bÃ¬nh giá»¯a giao dá»‹ch thÆ°á»ng vÃ  gian láº­n cÃ³ Ã½ nghÄ©a thá»‘ng kÃª khÃ´ng?

**Káº¿t quáº£**: 
- p-value = 0.0034 < 0.05
- **Káº¿t luáº­n**: BÃ¡c bá» H0. CÃ³ báº±ng chá»©ng thá»‘ng kÃª Ä‘á»§ máº¡nh Ä‘á»ƒ kháº³ng Ä‘á»‹nh ráº±ng **sá»‘ tiá»n giao dá»‹ch trung bÃ¬nh cá»§a hÃ nh vi gian láº­n khÃ¡c biá»‡t Ä‘Ã¡ng ká»ƒ so vá»›i giao dá»‹ch bÃ¬nh thÆ°á»ng**.

#### 6.2.2. Preprocessing Visualizations

**1. Outlier Detection Comparison**

- **IQR Method**: PhÃ¡t hiá»‡n Ä‘Æ°á»£c 370,372 outliers (4.33% tá»•ng sá»‘ data points)
  - CÃ¡c Ä‘áº·c trÆ°ng cÃ³ nhiá»u outliers nháº¥t: V27 (13.75%), Amount (11.20%), V28 (10.65%)
- **Z-score Method**: PhÃ¡t hiá»‡n Ä‘Æ°á»£c 83,598 outliers (0.98% tá»•ng sá»‘ data points)
  - PhÆ°Æ¡ng phÃ¡p nÃ y nghiÃªm ngáº·t hÆ¡n, chá»‰ phÃ¡t hiá»‡n cÃ¡c outliers cá»±c Ä‘oan

- **Quyáº¿t Ä‘á»‹nh**: **KHÃ”NG loáº¡i bá» outliers** vÃ¬:
  - Trong bÃ i toÃ¡n fraud detection, outliers cÃ³ thá»ƒ chÃ­nh lÃ  cÃ¡c giao dá»‹ch gian láº­n
  - Loáº¡i bá» outliers cÃ³ thá»ƒ lÃ m máº¥t Ä‘i nhá»¯ng máº«u quan trá»ng nháº¥t
  - Thay vÃ o Ä‘Ã³, sá»­ dá»¥ng cÃ¡c phÆ°Æ¡ng phÃ¡p chuáº©n hÃ³a máº¡nh (robust scaling)

**2. Normalization Comparison**

**Biá»ƒu Ä‘á»“**: Histograms so sÃ¡nh Original vs Min-Max vs Z-score vs Log-transformed cho feature Amount

![Min-Max Normalization Comparison](images/min_max_normalization.png)
![Z-score Standadization Comparison](images/z_score.png)
![Log Transformation Comparison](images/log_transformation.png)

**Giáº£i thÃ­ch**:
- **Original**: PhÃ¢n phá»‘i lá»‡ch pháº£i nghiÃªm trá»ng (Skewness = 16.98)
- **Min-Max Normalization**: ÄÆ°a vá» [0, 1], nhÆ°ng bá»‹ áº£nh hÆ°á»Ÿng máº¡nh bá»Ÿi outliers. Pháº§n lá»›n dá»¯ liá»‡u bá»‹ dá»“n vá» gáº§n giÃ¡ trá»‹ 0
- **Z-score Standardization**: ÄÆ°a vá» Mean=0, Std=1, nhÆ°ng váº«n chá»‹u áº£nh hÆ°á»Ÿng bá»Ÿi outliers. Dáº£i giÃ¡ trá»‹ sau khi chuáº©n hÃ³a váº«n ráº¥t rá»™ng
- **Log Transformation**: 
  - Giáº£m Ä‘á»™ lá»‡ch máº¡nh tá»« 16.98 xuá»‘ng 0.16
  - PhÃ¢n phá»‘i trá»Ÿ nÃªn cÃ¢n Ä‘á»‘i hÆ¡n ráº¥t nhiá»u, gáº§n vá»›i phÃ¢n phá»‘i chuáº©n (hÃ¬nh chuÃ´ng)
  - GiÃºp cÃ¡c mÃ´ hÃ¬nh há»c mÃ¡y há»c tá»‘t hÆ¡n

- **Quyáº¿t Ä‘á»‹nh cuá»‘i cÃ¹ng**: Káº¿t há»£p **Log Transformation** (Ä‘á»ƒ xá»­ lÃ½ phÃ¢n phá»‘i lá»‡ch) + **Z-score Standardization** (Ä‘á»ƒ Ä‘Æ°a vá» cÃ¹ng thang Ä‘o)

#### 6.2.3. Modeling Visualizations

**1. Training Loss History**

**Biá»ƒu Ä‘á»“**: Line chart hiá»ƒn thá»‹ Loss giáº£m Ä‘á»u qua cÃ¡c iterations

![](images/loss_history.png)

**Giáº£i thÃ­ch**:
- **Sá»± há»™i tá»¥**: ÄÆ°á»ng Loss giáº£m Ä‘á»u vÃ  mÆ°á»£t mÃ , tiá»‡m cáº­n vá» giÃ¡ trá»‹ ~0.1095 sau 1000 vÃ²ng láº·p
- **ÄÃ¡nh giÃ¡**: 
  - Thuáº­t toÃ¡n Gradient Descent hoáº¡t Ä‘á»™ng Ä‘Ãºng
  - Learning Rate `0.01` lÃ  phÃ¹ há»£p (khÃ´ng bá»‹ dao Ä‘á»™ng quÃ¡ máº¡nh hay há»™i tá»¥ quÃ¡ cháº­m)
  - Má»©c loss nÃ y khÃ¡ tháº¥p Ä‘á»‘i vá»›i bÃ i toÃ¡n phÃ¢n loáº¡i nhá»‹ phÃ¢n
  - KhÃ´ng cÃ³ dáº¥u hiá»‡u overfitting (loss khÃ´ng tÄƒng lÃªn)

**2. Confusion Matrix**

**CÃ¢u há»i**: Tá»« dá»± Ä‘oÃ¡n cá»§a mÃ´ hÃ¬nh, chÃºng ta cÃ³ thá»ƒ tháº¥y Ä‘Æ°á»£c gÃ¬ vá» kháº£ nÄƒng phÃ¡t hiá»‡n gian láº­n?

![](images/confusion_matrix.png)

**Biá»ƒu Ä‘á»“**: Heatmap trá»±c quan hÃ³a sá»‘ lÆ°á»£ng TP, TN, FP, FN (vá»›i Threshold = 0.2)

**Giáº£i thÃ­ch**:
- **True Negatives (56,844)**: Äa sá»‘ cÃ¡c giao dá»‹ch bÃ¬nh thÆ°á»ng Ä‘Æ°á»£c phÃ¢n loáº¡i Ä‘Ãºng
- **False Positives (19)**: Sá»‘ lÆ°á»£ng bÃ¡o Ä‘á»™ng giáº£ tháº¥p
  - Ã nghÄ©a: Chá»‰ cÃ³ 19 khÃ¡ch hÃ ng bá»‹ lÃ m phiá»n hoáº·c bá»‹ khÃ³a tháº» oan. Tá»· lá»‡ cá»±c ká»³ tháº¥p vÃ  hoÃ n toÃ n cháº¥p nháº­n Ä‘Æ°á»£c trong váº­n hÃ nh thá»±c táº¿.
- **False Negatives (20)**: Sá»‘ lÆ°á»£ng giao dá»‹ch gian láº­n bá»‹ bá» sÃ³t
  - Ã nghÄ©a: CÃ³ 20 vá»¥ gian láº­n bá»‹ bá» lá»t, gÃ¢y thiá»‡t háº¡i tÃ i chÃ­nh. Tuy nhiÃªn, con sá»‘ nÃ y Ä‘Ã£ giáº£m Ä‘Ã¡ng ká»ƒ so vá»›i threshold 0.5 (lÃºc Ä‘Ã³ >53 vá»¥ bá»‹ bá» sÃ³t).
- **True Positives (78)**: Sá»‘ lÆ°á»£ng gian láº­n báº¯t Ä‘Æ°á»£c (78/98 = 79.59%)

**Nháº­n Ä‘á»‹nh**:
- Sá»± Ä‘Ã¡nh Ä‘á»•i hiá»‡u quáº£: **FP (19) â‰ˆ FN (20)** cho tháº¥y viá»‡c háº¡ threshold xuá»‘ng 0.2 lÃ  quyáº¿t Ä‘á»‹nh há»£p lÃ½
- MÃ´ hÃ¬nh Logistic Regression Ä‘Æ¡n giáº£n nhÆ°ng phÃ¢n tÃ¡ch Ä‘Æ°á»£c pháº§n lá»›n (78/98) cÃ¡c giao dá»‹ch gian láº­n
- CÃ¡c Ä‘áº·c trÆ°ng PCA (V1-V28) cÃ³ cháº¥t lÆ°á»£ng cao vÃ  tÃ­nh phÃ¢n loáº¡i tá»‘t

**3. ROC Curve**

**Biá»ƒu Ä‘á»“**: Line chart hiá»ƒn thá»‹ ROC curve vá»›i AUC = 0.9748, so sÃ¡nh vá»›i Random Classifier (Ä‘Æ°á»ng chÃ©o)

![](images/roc_curve.png)

**Giáº£i thÃ­ch**:
- **ROC Curve**: ÄÆ°á»ng cong náº±m sÃ¡t gÃ³c trÃªn bÃªn trÃ¡i, cho tháº¥y kháº£ nÄƒng phÃ¢n tÃ¡ch giá»¯a hai lá»›p (Fraud vÃ  Normal) lÃ  ráº¥t tá»‘t
- **AUC Score (0.9748)**: Chá»‰ sá»‘ diá»‡n tÃ­ch dÆ°á»›i Ä‘Æ°á»ng cong Ä‘áº¡t 0.97 lÃ  má»™t káº¿t quáº£ **ráº¥t cao**
  - Top 5% trong cÃ¡c mÃ´ hÃ¬nh fraud detection
  - Chá»©ng tá» mÃ´ hÃ¬nh cÃ³ kháº£ nÄƒng phÃ¢n biá»‡t tá»‘t giá»¯a Normal vÃ  Fraud

- **Káº¿t luáº­n quan trá»ng**:
  - **AUC cao** lÃ  lÃ½ do chÃºng ta cÃ³ thá»ƒ tune threshold Ä‘á»ƒ cáº£i thiá»‡n Recall
  - Viá»‡c háº¡ threshold tá»« 0.5 xuá»‘ng 0.2 Ä‘Ã£ Ä‘Æ°á»£c thá»±c hiá»‡n vÃ  mang láº¡i káº¿t quáº£ tá»‘t

- **Káº¿t quáº£ sau khi tá»‘i Æ°u threshold**:
  - Háº¡ ngÆ°á»¡ng tá»« $0.5$ xuá»‘ng $0.2$ Ä‘Ã£ giÃºp:
    - **Recall tÄƒng tá»« 45.92% lÃªn 79.59%** (báº¯t Ä‘Æ°á»£c thÃªm 33 vá»¥ gian láº­n)
    - **Precision chá»‰ giáº£m nháº¹ tá»« 83.33% xuá»‘ng 80.41%** (thÃªm 10 cáº£nh bÃ¡o giáº£)
    - **F1-Score tÄƒng tá»« 0.5921 lÃªn 0.8000** (cÃ¢n báº±ng tá»‘t hÆ¡n háº³n)

### 6.3. So sÃ¡nh vÃ  phÃ¢n tÃ­ch

#### 6.3.1. Äiá»ƒm máº¡nh cá»§a mÃ´ hÃ¬nh (vá»›i Threshold = 0.2)

1. **AUC Score cao (0.9748)**:
   - Chá»©ng tá» mÃ´ hÃ¬nh cÃ³ kháº£ nÄƒng phÃ¢n biá»‡t tá»‘t giá»¯a Normal vÃ  Fraud
   - Top 5% trong cÃ¡c mÃ´ hÃ¬nh fraud detection

2. **Recall cao (0.7959)**:
   - PhÃ¡t hiá»‡n Ä‘Æ°á»£c gáº§n 80% tá»•ng sá»‘ gian láº­n
   - Cáº£i thiá»‡n Ä‘á»™t phÃ¡ so vá»›i threshold máº·c Ä‘á»‹nh 0.5

3. **F1-Score cÃ¢n báº±ng (0.8000)**:
   - CÃ¢n báº±ng tá»‘t giá»¯a Precision vÃ  Recall
   - PhÃ¹ há»£p cho bÃ i toÃ¡n fraud detection

4. **Training á»•n Ä‘á»‹nh**:
   - Loss giáº£m Ä‘á»u, khÃ´ng cÃ³ dáº¥u hiá»‡u overfitting
   - Gradient Descent hoáº¡t Ä‘á»™ng tá»‘t

#### 6.3.2. Äiá»ƒm yáº¿u vÃ  háº¡n cháº¿

1. **Váº«n cÃ²n bá» sÃ³t 20 vá»¥ gian láº­n**:
   - Recall chÆ°a Ä‘áº¡t 100%, váº«n cÃ³ rá»§i ro thiá»‡t háº¡i tÃ i chÃ­nh
   - Cáº§n cÃ¢n nháº¯c káº¿t há»£p vá»›i cÃ¡c mÃ´ hÃ¬nh khÃ¡c

2. **False Positives (19 cáº£nh bÃ¡o giáº£)**:
   - LÃ m phiá»n má»™t sá»‘ Ã­t khÃ¡ch hÃ ng vÃ´ tá»™i
   - ÄÃ¢y lÃ  sá»± Ä‘Ã¡nh Ä‘á»•i cáº§n thiáº¿t Ä‘á»ƒ tÄƒng Recall

3. **Class imbalance**:
   - Dá»¯ liá»‡u máº¥t cÃ¢n báº±ng nghiÃªm trá»ng (0.17% Fraud)
   - CÃ³ thá»ƒ cáº£i thiá»‡n thÃªm báº±ng SMOTE hoáº·c Class Weights

#### 6.3.3. So sÃ¡nh vá»›i Baseline

**Baseline (Dá»± Ä‘oÃ¡n táº¥t cáº£ lÃ  Normal)**:
- Accuracy: 0.9983
- Precision: 0.0 (khÃ´ng cÃ³ TP)
- Recall: 0.0 (khÃ´ng phÃ¡t hiá»‡n Ä‘Æ°á»£c fraud nÃ o)
- F1-Score: 0.0

**MÃ´ hÃ¬nh Logistic Regression (Threshold = 0.2)**:
- Accuracy: 0.9993 (+0.0010)
- Precision: 0.8041 (tá»‘t)
- Recall: 0.7959 (cáº£i thiá»‡n Ä‘á»™t phÃ¡)
- F1-Score: 0.8000 (tá»‘t)

**Káº¿t luáº­n**: MÃ´ hÃ¬nh tá»‘t hÆ¡n baseline Ä‘Ã¡ng ká»ƒ, phÃ¡t hiá»‡n Ä‘Æ°á»£c gáº§n 80% vá»¥ gian láº­n vá»›i Ä‘á»™ chÃ­nh xÃ¡c cao.

#### 6.3.4. Insights quan trá»ng

1. **PCA Features quan trá»ng**:
   - V3, V14, V17, V12, V10, V7, V1 lÃ  nhá»¯ng features quan trá»ng nháº¥t
   - CÃ³ sá»± khÃ¡c biá»‡t lá»›n giá»¯a Normal vÃ  Fraud (V3: diff = 7.05, V14: diff = 6.98)

2. **Time pattern**:
   - Fraud rate cao nháº¥t vÃ o ban Ä‘Ãªm: **2h sÃ¡ng** (tá»· lá»‡ ~1.71%)
   - Fraud rate tháº¥p nháº¥t vÃ o ban ngÃ y: **10h sÃ¡ng** (tá»· lá»‡ ~0.05%)
   - Má»‘i quan há»‡ nghá»‹ch: Khi transaction volume giáº£m, fraud rate tÄƒng

3. **Amount distribution**:
   - Fraud cÃ³ mean cao hÆ¡n ($122.21 vs $88.29) nhÆ°ng median tháº¥p hÆ¡n ($9.25 vs $22.00)
   - Log transformation giáº£m skewness tá»« 16.98 xuá»‘ng 0.16
   - T-test: p-value = 0.0034 < 0.05 â†’ Sá»± khÃ¡c biá»‡t cÃ³ Ã½ nghÄ©a thá»‘ng kÃª

4. **Threshold optimization Ä‘Ã£ thá»±c hiá»‡n**:
   - Háº¡ threshold tá»« 0.5 xuá»‘ng 0.2 mang láº¡i cáº£i thiá»‡n Ä‘á»™t phÃ¡
   - Recall tÄƒng tá»« 45.92% lÃªn 79.59%
   - F1-Score tÄƒng tá»« 0.5921 lÃªn 0.8000
   - ÄÃ¢y lÃ  trade-off hiá»‡u quáº£: Chá»‰ thÃªm 10 FP Ä‘á»ƒ báº¯t thÃªm 33 TP

---

## 7. Project Structure

```
23127516/
â”œâ”€â”€ README.md                          # File README
â”œâ”€â”€ requirements.txt                   # Danh sÃ¡ch cÃ¡c thÆ° viá»‡n cáº§n thiáº¿t
â”‚
â”œâ”€â”€ data/                              # ThÆ° má»¥c chá»©a dá»¯ liá»‡u
â”‚   â”œâ”€â”€ raw/                           # Dá»¯ liá»‡u gá»‘c
â”‚   â”‚   â””â”€â”€ creditcard.csv             # Dataset gá»‘c tá»« Kaggle
â”‚   â””â”€â”€ processed/                     # Dá»¯ liá»‡u Ä‘Ã£ xá»­ lÃ½
â”‚       â”œâ”€â”€ X_train.npy                # Features táº­p train (227,846 máº«u)
â”‚       â”œâ”€â”€ X_test.npy                 # Features táº­p test (56,961 máº«u)
â”‚       â”œâ”€â”€ y_train.npy                # Labels táº­p train
â”‚       â””â”€â”€ y_test.npy                 # Labels táº­p test
â”‚
â””â”€â”€ notebooks/                         # ThÆ° má»¥c chá»©a cÃ¡c Jupyter notebooks
    â”œâ”€â”€ 01_data_exploration.ipynb      # Notebook khÃ¡m phÃ¡ dá»¯ liá»‡u
    â”œâ”€â”€ 02_preprocessing.ipynb         # Notebook tiá»n xá»­ lÃ½ dá»¯ liá»‡u
    â””â”€â”€ 03_modeling.ipynb              # Notebook huáº¥n luyá»‡n vÃ  Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh
```

### 7.1. Giáº£i thÃ­ch chá»©c nÄƒng tá»«ng file/folder

#### `data/raw/`
- **Chá»©c nÄƒng**: Chá»©a dá»¯ liá»‡u gá»‘c tá»« dataset Kaggle
- **File**: `creditcard.csv` - Dataset gá»‘c vá»›i 284,807 giao dá»‹ch vÃ  31 cá»™t

#### `data/processed/`
- **Chá»©c nÄƒng**: Chá»©a dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c xá»­ lÃ½ qua cÃ¡c bÆ°á»›c preprocessing
- **Files**:
  - `X_train.npy`: Features táº­p train (227,846 máº«u, 30 features)
  - `X_test.npy`: Features táº­p test (56,961 máº«u, 30 features)
  - `y_train.npy`: Labels táº­p train (0 = Normal, 1 = Fraud)
  - `y_test.npy`: Labels táº­p test

#### `notebooks/01_data_exploration.ipynb`
- **Chá»©c nÄƒng**: KhÃ¡m phÃ¡ vÃ  phÃ¢n tÃ­ch dá»¯ liá»‡u ban Ä‘áº§u
- **Ná»™i dung chÃ­nh**:
  1. Load dataset báº±ng NumPy
  2. Kiá»ƒm tra missing values vÃ  thá»‘ng kÃª mÃ´ táº£
  3. PhÃ¢n tÃ­ch class distribution
  4. PhÃ¢n tÃ­ch cÃ¡c features quan trá»ng (Time, Amount, V1-V28)
  5. Correlation analysis
  6. So sÃ¡nh features giá»¯a Normal vÃ  Fraud
  7. Feature engineering (rolling statistics)
  8. Statistical hypothesis testing
  9. Xá»­ lÃ½ missing values (demo)
  10. LÆ°u dá»¯ liá»‡u Ä‘Ã£ xá»­ lÃ½

#### `notebooks/02_preprocessing.ipynb`
- **Chá»©c nÄƒng**: Tiá»n xá»­ lÃ½ dá»¯ liá»‡u trÆ°á»›c khi modeling
- **Ná»™i dung chÃ­nh**:
  1. Load dá»¯ liá»‡u tá»« notebook 01
  2. Outlier detection (IQR vÃ  Z-score methods)
  3. Normalization & Standardization:
     - Min-Max Normalization
     - Z-score Standardization
     - Log Transformation
     - Decimal Scaling
  4. Ãp dá»¥ng preprocessing cuá»‘i cÃ¹ng (Log + Z-score)
  5. Train-Test Split (80-20)
  6. LÆ°u dá»¯ liá»‡u Ä‘Ã£ xá»­ lÃ½

#### `notebooks/03_modeling.ipynb`
- **Chá»©c nÄƒng**: Huáº¥n luyá»‡n vÃ  Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh Logistic Regression
- **Ná»™i dung chÃ­nh**:
  1. Load dá»¯ liá»‡u Ä‘Ã£ xá»­ lÃ½ tá»« notebook 02
  2. Implement cÃ¡c evaluation metrics (Accuracy, Precision, Recall, F1, AUC)
  3. Implement Logistic Regression class tá»« Ä‘áº§u
  4. Training mÃ´ hÃ¬nh vá»›i Gradient Descent
  5. Visualize training loss history
  6. Evaluation trÃªn test set vá»›i threshold máº·c Ä‘á»‹nh (0.5)
  7. **Threshold optimization**: Thá»­ nghiá»‡m vá»›i threshold = 0.2
  8. Váº½ Confusion Matrix
  9. Váº½ ROC Curve vÃ  tÃ­nh AUC
  10. PhÃ¢n tÃ­ch vÃ  Ä‘Ã¡nh giÃ¡ káº¿t quáº£

#### `requirements.txt`
- **Chá»©c nÄƒng**: Liá»‡t kÃª cÃ¡c thÆ° viá»‡n Python cáº§n thiáº¿t
- **Ná»™i dung**:
  ```
  numpy>=1.21.0
  matplotlib>=3.5.0
  seaborn>=0.11.0
  ```

#### `README.md`
- **Chá»©c nÄƒng**: TÃ i liá»‡u hÆ°á»›ng dáº«n chi tiáº¿t vá» dá»± Ã¡n
- **Ná»™i dung**: MÃ´ táº£ Ä‘áº§y Ä‘á»§ vá» project, dataset, methods, results, vÃ  hÆ°á»›ng dáº«n sá»­ dá»¥ng

---

## 8. Challenges & Solutions

### KhÃ³ khÄƒn gáº·p pháº£i khi dÃ¹ng NumPy

### 8.1. Challenge: Load CSV file khÃ´ng dÃ¹ng Pandas

**Váº¥n Ä‘á»**:
- NumPy khÃ´ng cÃ³ hÃ m Ä‘á»c CSV trá»±c tiáº¿p nhÆ° Pandas (`pd.read_csv()`)
- Cáº§n parse header vÃ  convert data types thá»§ cÃ´ng
- File CSV cÃ³ header vá»›i dáº¥u ngoáº·c kÃ©p (`"Time"`, `"V1"`, ...)

**Solution - Ã tÆ°á»Ÿng triá»ƒn khai**:
- Sá»­ dá»¥ng `np.genfromtxt()` vá»›i `dtype=str` Ä‘á»ƒ Ä‘á»c file CSV vÃ  giá»¯ nguyÃªn format ban Ä‘áº§u
- Sá»­ dá»¥ng `np.char.strip()` Ä‘á»ƒ loáº¡i bá» dáº¥u ngoáº·c kÃ©p tá»« header
- TÃ¡ch header vÃ  dá»¯ liá»‡u, sau Ä‘Ã³ convert sang `float64` Ä‘á»ƒ cÃ³ thá»ƒ tÃ­nh toÃ¡n

**BÃ i há»c**: NumPy cÃ³ `np.char` module Ä‘á»ƒ xá»­ lÃ½ string arrays, vÃ  `np.genfromtxt()` cÃ³ thá»ƒ Ä‘á»c CSV nhÆ°ng cáº§n xá»­ lÃ½ thÃªm.

### 8.2. Challenge: Vectorization thay vÃ¬ for loops

**Váº¥n Ä‘á»**:
- Ban Ä‘áº§u cÃ³ thá»ƒ muá»‘n dÃ¹ng for loops Ä‘á»ƒ xá»­ lÃ½ tá»«ng feature
- For loops cháº­m vá»›i dataset lá»›n (284,807 samples)
- Cáº§n tÃ­nh toÃ¡n thá»‘ng kÃª cho nhiá»u features

**Solution - Ã tÆ°á»Ÿng triá»ƒn khai**:

**VÃ­ dá»¥ 1: TÃ­nh mean cho táº¥t cáº£ features**
- Thay vÃ¬ dÃ¹ng for loop qua tá»«ng feature, sá»­ dá»¥ng `np.mean(data, axis=0)` Ä‘á»ƒ tÃ­nh mean theo axis=0 (columns) má»™t láº§n duy nháº¥t

**VÃ­ dá»¥ 2: TÃ­nh Z-score cho táº¥t cáº£ features**
- Sá»­ dá»¥ng broadcasting: TÃ­nh mean vÃ  std vá»›i `keepdims=True` Ä‘á»ƒ giá»¯ shape (1, n_features)
- Ãp dá»¥ng broadcasting Ä‘á»ƒ tÃ­nh Z-score cho toÃ n bá»™ ma tráº­n má»™t láº§n: `(data - mean_vals) / std_vals`

**VÃ­ dá»¥ 3: Fancy indexing thay vÃ¬ loop + if**
- Thay vÃ¬ dÃ¹ng for loop vá»›i if statement, sá»­ dá»¥ng boolean indexing: `fraud_mask = (y == 1)` rá»“i `fraud_data = X[fraud_mask]`

**BÃ i há»c**: LuÃ´n nghÄ© vá» cÃ¡ch vectorize operations, sá»­ dá»¥ng broadcasting vÃ  fancy indexing Ä‘á»ƒ tÄƒng tá»‘c Ä‘á»™ tÃ­nh toÃ¡n.

### 8.3. Challenge: Numerical stability trong sigmoid

**Váº¥n Ä‘á»**:
- `exp(-z)` cÃ³ thá»ƒ overflow khi z ráº¥t Ã¢m (z << 0)
- `exp(z)` cÃ³ thá»ƒ overflow khi z ráº¥t dÆ°Æ¡ng (z >> 0)
- Dáº«n Ä‘áº¿n `sigmoid(z)` tráº£ vá» `nan` hoáº·c `inf`

**Solution - Ã tÆ°á»Ÿng triá»ƒn khai**:
- Sá»­ dá»¥ng `np.clip(z, -500, 500)` Ä‘á»ƒ giá»›i háº¡n giÃ¡ trá»‹ z trong khoáº£ng [-500, 500]
- Vá»›i z trong khoáº£ng nÃ y, sigmoid hoáº¡t Ä‘á»™ng á»•n Ä‘á»‹nh:
  - `exp(-500) â‰ˆ 0` â†’ `sigmoid(-500) â‰ˆ 0`
  - `exp(500) â‰ˆ inf` â†’ `sigmoid(500) â‰ˆ 1`

**BÃ i há»c**: LuÃ´n chÃº Ã½ Ä‘áº¿n numerical stability, Ä‘áº·c biá»‡t vá»›i cÃ¡c hÃ m exponential.

### 8.4. Challenge: TÃ­nh toÃ¡n thá»‘ng kÃª phá»©c táº¡p (Skewness, Kurtosis)

**Váº¥n Ä‘á»**:
- NumPy khÃ´ng cÃ³ hÃ m `skew()` vÃ  `kurtosis()` sáºµn
- Cáº§n implement tá»« Ä‘áº§u báº±ng cÃ´ng thá»©c toÃ¡n há»c

**Solution - Ã tÆ°á»Ÿng triá»ƒn khai**:
- Implement tá»« cÃ´ng thá»©c toÃ¡n há»c:
  - Skewness: TÃ­nh mean vÃ  std, sau Ä‘Ã³ tÃ­nh mean cá»§a `((x - mean) / std)^3`
  - Kurtosis: TÃ­nh mean vÃ  std, sau Ä‘Ã³ tÃ­nh mean cá»§a `((x - mean) / std)^4 - 3` (excess kurtosis)
- Sá»­ dá»¥ng vectorization Ä‘á»ƒ tÃ­nh cho táº¥t cáº£ features cÃ¹ng lÃºc
- Xá»­ lÃ½ edge case: Náº¿u std = 0 thÃ¬ thay báº±ng 1 Ä‘á»ƒ trÃ¡nh division by zero

**BÃ i há»c**: Hiá»ƒu rÃµ cÃ´ng thá»©c toÃ¡n há»c giÃºp implement cÃ¡c hÃ m khÃ´ng cÃ³ sáºµn.

### 8.5. Challenge: Xá»­ lÃ½ division by zero

**Váº¥n Ä‘á»**:
- Khi tÃ­nh Z-score, náº¿u std = 0 (feature khÃ´ng Ä‘á»•i), sáº½ gÃ¢y lá»—i division by zero
- Khi tÃ­nh cÃ¡c metrics, náº¿u denominator = 0, sáº½ gÃ¢y lá»—i

**Solution - Ã tÆ°á»Ÿng triá»ƒn khai**:
- Sá»­ dá»¥ng `np.where()` Ä‘á»ƒ xá»­ lÃ½ edge cases:
  - VÃ­ dá»¥: `std_vals = np.where(std_vals == 0, 1, std_vals)` Ä‘á»ƒ thay 0 báº±ng 1
- Kiá»ƒm tra Ä‘iá»u kiá»‡n trÆ°á»›c khi tÃ­nh toÃ¡n:
  - VÃ­ dá»¥: Náº¿u `tp + fp == 0` thÃ¬ return 0.0 thay vÃ¬ chia cho 0

**BÃ i há»c**: LuÃ´n kiá»ƒm tra edge cases vÃ  xá»­ lÃ½ division by zero.

---

## 9. Future Improvements

### 9.1. Xá»­ lÃ½ Class Imbalance

**SMOTE (Synthetic Minority Oversampling Technique)**

**Ã tÆ°á»Ÿng**: Táº¡o cÃ¡c máº«u synthetic cho class thiá»ƒu sá»‘

- Sá»­ dá»¥ng k-nearest neighbors Ä‘á»ƒ táº¡o cÃ¡c máº«u má»›i cho class Fraud
- GiÃºp cÃ¢n báº±ng dataset mÃ  khÃ´ng lÃ m máº¥t thÃ´ng tin nhÆ° undersampling

**Undersampling**

**Ã tÆ°á»Ÿng**: Giáº£m sá»‘ lÆ°á»£ng máº«u cá»§a class Ä‘a sá»‘

- Random undersampling hoáº·c Tomek Links Ä‘á»ƒ loáº¡i bá» cÃ¡c máº«u khÃ´ng quan trá»ng cá»§a class Normal
- Cáº§n cáº©n tháº­n Ä‘á»ƒ khÃ´ng lÃ m máº¥t thÃ´ng tin quan trá»ng

### 9.2. Model Improvements

**Ensemble Methods**

**Ã tÆ°á»Ÿng**: Káº¿t há»£p nhiá»u mÃ´ hÃ¬nh Ä‘á»ƒ cáº£i thiá»‡n hiá»‡u suáº¥t

- CÃ³ thá»ƒ káº¿t há»£p Logistic Regression vá»›i cÃ¡c mÃ´ hÃ¬nh khÃ¡c (náº¿u Ä‘Æ°á»£c phÃ©p sá»­ dá»¥ng thÆ° viá»‡n)
- Voting hoáº·c Stacking Ä‘á»ƒ táº­n dá»¥ng Ä‘iá»ƒm máº¡nh cá»§a tá»«ng mÃ´ hÃ¬nh

### 9.3. Performance Improvements

**Parallel Processing**

**Ã tÆ°á»Ÿng**: Sá»­ dá»¥ng multiprocessing cho cÃ¡c tÃ­nh toÃ¡n song song

- CÃ³ thá»ƒ parallelize cross-validation hoáº·c feature engineering
- Sá»­ dá»¥ng `multiprocessing` module cá»§a Python

---

## 10. Contributors

### 10.1. ThÃ´ng tin tÃ¡c giáº£

- **TÃªn**: BÃ¹i Nam Viá»‡t
- **MSSV**: 23127516
- **TrÆ°á»ng**: TrÆ°á»ng Äáº¡i há»c Khoa há»c Tá»± nhiÃªn, Äáº¡i há»c Quá»‘c gia TP.HCM
- **Khoa**: Khoa CÃ´ng nghá»‡ ThÃ´ng tin
- **Bá»™ mÃ´n**: Nháº­p mÃ´n Khoa há»c Dá»¯ liá»‡u

### 10.2. Acknowledgments

- **Dataset**: Cáº£m Æ¡n ULB Machine Learning Group vÃ  Kaggle Ä‘Ã£ cung cáº¥p dataset
- **Giáº£ng viÃªn**: Cáº£m Æ¡n giáº£ng viÃªn mÃ´n Programming for Data Science Ä‘Ã£ hÆ°á»›ng dáº«n
- **TÃ i liá»‡u**: Cáº£m Æ¡n cá»™ng Ä‘á»“ng NumPy, Matplotlib, Seaborn Ä‘Ã£ cung cáº¥p tÃ i liá»‡u tuyá»‡t vá»i
- **Há»— trá»£ tá»« AI (Gemini, ChatGPT)**:
   - Giáº£i thÃ­ch chi tiáº¿t cÃ¡c Ä‘oáº¡n mÃ£ nguá»“n phá»©c táº¡p
   - Äá» xuáº¥t cÃ¡ch optimize code báº±ng NumPy vectorization
   - Cáº£i thiá»‡n code quality vÃ  best practices
   - Há»— trá»£ debugging vÃ  xá»­ lÃ½ edge cases
   - Giáº£i thÃ­ch cÃ¡c khÃ¡i niá»‡m toÃ¡n há»c Ä‘áº±ng sau cÃ¡c thuáº­t toÃ¡n
   - Gá»£i Ã½ cÃ¡c phÆ°Æ¡ng phÃ¡p alternative cho cÃ¡c bÃ i toÃ¡n láº­p trÃ¬nh

---

## 11. License

This project is licensed under the **Database Contents License (DbCL) v1.0**

## References

1. **NumPy Documentation**: https://drive.google.com/drive/folders/1FyzNTCs_xpx-CUVBw_VwXlEt73tf8ywX
2. **Credit Card Fraud Detection Dataset**: https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud
3. **Matplotlib Documentation**: https://matplotlib.org/
4. **Logistic Regression Theory**: https://machinelearningcoban.com/2017/01/27/logisticregression/

---
